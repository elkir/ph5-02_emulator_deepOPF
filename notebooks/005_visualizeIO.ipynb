{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize I and O tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "# from torchvision.utils import make_grid\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "# matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
    "\n",
    "# Logging ML\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd785cd9c30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(    \n",
    "    learning_rate =1e-3,\n",
    "    # batch_size =128,\n",
    "    epochs = int(3e3),\n",
    "    model=\"nn3\",\n",
    "    layers = [256,128,128,64],\n",
    "    training_loss = \"MSE+tP\",\n",
    "    alpha= 1e-6,\n",
    "    # scheduler = \"one-cycle-lr\",\n",
    "    years=[\"2011\",\"2013\",\"2014\"],\n",
    "    years_val=[\"2012\"],\n",
    "    nodes=\"37\"\n",
    ")\n",
    "use_tb = False\n",
    "use_wandb= True\n",
    "manual_logging = False\n",
    "check_data_with_plots = False\n",
    "\n",
    "project_name = f\"phd-ph5x-02-power_prediction_{config['nodes']}\"\n",
    "\n",
    "random_seed = 746435\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otherwise all files present\n"
     ]
    }
   ],
   "source": [
    "dir_root = Path(\"../\") # go to root of git repo\n",
    "dir_data = dir_root / \"data\"\n",
    "dir_data_ml= dir_data /\"ml\"\n",
    "dir_models = dir_root / \"models\"\n",
    "dir_runs = dir_root/\"runs\"\n",
    "dir_runs_tb = dir_runs /\"tb\"\n",
    "dir_runs_wandb = dir_root / \"wandb\"\n",
    "param_save = \"002_01_simplest\"\n",
    "\n",
    "network_name = f\"elec_s_{config['nodes']}_ec_lcopt_Co2L-3H\"\n",
    "\n",
    "dir_training_set = [dir_data_ml / y / \"3M\" for y in config[\"years\"]]\n",
    "filenames_inputs_tr = [d / f\"{network_name}_inputs.P\" for d in dir_training_set]\n",
    "filenames_outputs_tr = [d / f\"{network_name}_outputs_p.P\" for d in dir_training_set]\n",
    "\n",
    "dir_val_set = [ dir_data_ml / y/ \"3M\" for y in  config[\"years_val\"]]\n",
    "filenames_inputs_val = [d / f\"{network_name}_inputs.P\" for d in dir_val_set]\n",
    "filenames_outputs_val = [d / f\"{network_name}_outputs_p.P\" for d in dir_val_set]\n",
    "\n",
    "for fn in [*filenames_inputs_tr, *filenames_outputs_tr,\n",
    "           *filenames_inputs_val,*filenames_outputs_val]:\n",
    "    if not fn.exists():\n",
    "        print(f\"{fn}: Missing\")\n",
    "print(\"Otherwise all files present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 37, 8760, 2928)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_all_dfs(filenames):\n",
    "    return pd.concat([pd.read_pickle(f) for f in filenames])\n",
    "\n",
    "df_input_tr = read_all_dfs(filenames_inputs_tr)\n",
    "df_output_tr = read_all_dfs(filenames_outputs_tr)\n",
    "df_input_val = read_all_dfs(filenames_inputs_val)\n",
    "df_output_val = read_all_dfs(filenames_outputs_val)\n",
    "\n",
    "\n",
    "assert (df_input_val.columns==df_input_tr.columns).all(), \"Mismatch in input columns\"\n",
    "assert (df_output_val.columns==df_output_tr.columns).all(), \"Mismatch in output columns\"\n",
    "input_features = df_input_val.columns\n",
    "output_features = df_output_val.columns\n",
    "\n",
    "x_train = torch.from_numpy(df_input_tr.values.astype(\"float32\"))\n",
    "y_train = torch.from_numpy(df_output_tr.values.astype(\"float32\"))\n",
    "x_val = torch.from_numpy(df_input_val.values.astype(\"float32\"))\n",
    "y_val = torch.from_numpy(df_output_val.values.astype(\"float32\"))\n",
    "\n",
    "n_input = x_train.shape[1]\n",
    "n_output = y_train.shape[1]\n",
    "n_samples_tr = x_train.shape[0]\n",
    "n_samples_val = x_val.shape[0]\n",
    "\n",
    "# Normalization defined by training data\n",
    "x_mean = x_train.mean(dim = 0)\n",
    "x_std =x_train.std(dim = 0)\n",
    "y_mean = torch.zeros(n_output)  # centered already\n",
    "y_std = y_train.std(dim = 0)\n",
    "\n",
    "def x_norm(x): return (x-x_mean)/x_std\n",
    "def y_norm(y): return (y-y_mean)/y_std\n",
    "def x_renorm(x): return x*x_std+x_mean\n",
    "def y_renorm(y): return y*y_std+y_mean\n",
    "\n",
    "\n",
    "x_train =  x_norm(x_train)\n",
    "y_train = y_norm(y_train)\n",
    "\n",
    "x_val = x_norm(x_val)\n",
    "y_val = y_norm(y_val)\n",
    "y_renorm(y_train).sum(dim=1)\n",
    "assert not(((x_val[0:100]-x_train[0:100])<1e-5).all()), \"Training data identical to validation data\"\n",
    "\n",
    "\n",
    "(n_input,n_output,n_samples_tr,n_samples_val)\n",
    "# train_loader = load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort generator technologies\n",
    "col= df_input_tr.columns\n",
    "sorted_gen =col[col.str.startswith(\"generators\")].str.split(\" \").str[3].argsort()\n",
    "ngen =col.str.startswith(\"gen\").sum()\n",
    "index_sorted_technologies = np.concatenate([sorted_gen,list(range(ngen,len(col)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  94,  47,  89,  84,  25,  76,  98,  71,  66,  61,  34,  56,\n",
       "        38,  51,  30, 106,  42, 111,  14, 117, 148, 121,   9, 126, 143,\n",
       "       131, 135,  99,  48, 144,  52,  57, 136, 127, 107,  67,  72, 122,\n",
       "        85, 118,  62,  90,  77,  26,  10,  31,  39,  15,  35,  43,  81,\n",
       "       140,  86,  22, 137,  91,   4,  95,  19,  44,  78,  16, 108, 132,\n",
       "       112, 115, 119, 128,  11, 123, 100, 103,   7,   1,  32,  63,  58,\n",
       "       145,  36,  68,  53,  73, 149,  40,  27,  49, 152,  54, 109,  59,\n",
       "       113,  17, 133, 104, 150, 101,  74,  96,   5,  45, 153,  28,  79,\n",
       "       141,  82,  69, 124,  23,  87, 138,   2,  64,  92,  20, 129, 146,\n",
       "        12, 151, 147,   6, 134,   3, 142, 130, 139,  18, 125,  46,  41,\n",
       "        50,  37,  55,  60,  33,  65,  29,  70,  75,  80,  83,  24,  88,\n",
       "        21,  93,  97, 102, 105, 110, 114, 116,  13, 120,   8, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_sorted_technologies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as grd\n",
    "\n",
    "\n",
    "N=3000\n",
    "x=x_train[3000:3000+N]\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "# N=pca.n_components_\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14,9))\n",
    "# create a 1 X 2 grid \n",
    "gs = grd.GridSpec(1, 2, width_ratios=[20,1])#, wspace=0.1)\n",
    "\n",
    "# image plot\n",
    "ax = [plt.subplot(g) for g in gs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['offwind-ac', 'offwind-ac', 'offwind-ac', 'offwind-ac', 'offwind-ac',\n",
       "       'offwind-ac', 'offwind-ac', 'offwind-ac', 'offwind-ac', 'offwind-ac',\n",
       "       ...\n",
       "       'hydro', 'hydro', 'hydro', 'hydro', 'hydro', 'hydro', 'hydro', 'hydro',\n",
       "       'hydro', 'hydro'],\n",
       "      dtype='object', length=219)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_tech =  col[df_input_tr.columns.argsort()][index_sorted_technologies].str.split(\" \").str[-1]\n",
    "input_tech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= col[df_input_tr.columns.argsort()][index_sorted_technologies].str.split(\" \").str[-1].value_counts(sort=False).values\n",
    "x_ticks_major = a.cumsum()\n",
    "x_ticks_minor = x_ticks_major - a/2\n",
    "\n",
    "x_labels_major= input_tech.to_series().replace({'0':'load',\"hydro\":\"hydro:inflow\"}).unique()\n",
    "# b = pd.DataFrame(index_outputs).groupby(0)[2].sum()[x_labels_major].values\n",
    "# b[0]-=3\n",
    "# x_ticks_major = b.cumsum()\n",
    "# x_labels_major = [ f\"{x[:-2]}:{y} ⇥\"  for x,y,_ in index_outputs] #⇥\n",
    "\n",
    "# fig,ax = plt.subplots(1,2,gridspec_kw=dict(width_ratios=[9,1]),figsize=(10,9),sharey='all')\n",
    "cmap =  cm.magma\n",
    "cmap.set_bad('k',1.)\n",
    "ax[0].imshow(x[:,df_input_tr.columns.argsort()][:,index_sorted_technologies].T, cmap=cmap, aspect='auto')\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].set_xticks(x_ticks_minor, minor=True)\n",
    "ax[0].set_xticklabels(a, minor=True,size=8)\n",
    "\n",
    "ax[0].set_xticks(x_ticks_major, minor=False)\n",
    "ax[0].set_xticklabels(x_labels_major, minor=False,rotation=-20)\n",
    "for label in ax[0].get_xticklabels():\n",
    "    label.set_horizontalalignment('right')\n",
    "ax[0].set_ylabel(\"PCA components\\n(most prominent at the top)\")\n",
    "ax[0].tick_params('x', length=5, width=2, which='major')\n",
    "ax[0].tick_params('x', length=0, width=1, which='minor')\n",
    "\n",
    "\n",
    "# ax[1].fill_betweenx(np.arange(N),1e-33,pca.explained_variance_ratio_[:N],\n",
    "#               color ='xkcd:royal purple')\n",
    "# ax[1].set_xlim(1e-33,1e0)\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_xticks([1e-33,1e0])\n",
    "# ax[1].yaxis.tick_right()\n",
    "# ax[1].set_ylim(0,N)\n",
    "# ax[1].invert_yaxis()\n",
    "# ax[1].set_ylabel('Variance ratio (log)')\n",
    "# ax[1].yaxis.set_label_position(\"right\")\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"outputs_PCA_all.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_data_with_plots:\n",
    "    n_min=min(n_samples_val,n_samples_tr)\n",
    "    _=plt.plot(x_train[:n_min], \"r\", alpha = 0.1) # [:,38:192]\n",
    "    _=plt.plot(y_train[:n_min], \"b\", alpha = 0.1) # [:,38:192]\n",
    "    _=plt.plot(x_val[:n_min], \"m\", alpha = 0.1) # [:,38:192]\n",
    "    _=plt.plot(y_val[:n_min], \"c\", alpha = 0.1) # [:,38:192]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('phd_ph5x-02_emulator_deepOPF_pypsa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b392f132ec8d9f75c9dc3d7bf67657658141c2cfa78fd6226f20eb67aeb16219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
